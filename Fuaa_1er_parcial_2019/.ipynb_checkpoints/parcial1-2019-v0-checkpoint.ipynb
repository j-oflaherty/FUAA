{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> FUNDAMENTOS DE APRENDIZAJE AUTOMÁTICO <br> Y RECONOCIMIENTO DE PATRONES</center>\n",
    "## <center> 1er parcial, 2019</center>           \n",
    "\n",
    "El parcial consta de 3 ejercicios. La duración del parcial es de 3 horas. El parcial es sin material y no está permitido acceder a Internet. Ante cualquier duda comuníquese con los docentes.\n",
    "\n",
    "* [Ejercicio 1 - Teoría de la generalización](#Ejercicio1)\n",
    "* [Ejercicio 2 - Regresión logística](#Ejercicio2)\n",
    "* [Ejercicio 3 - Clasificación de dígitos](#Ejercicio3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se importan las biblotecas que se van a utilizar\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import h5py # es el formato en el que están almacenados los dígitos\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10.0, 10.0) # tamaño de las figuras por defecto\n",
    "# el inline sirve para que las figuras se muestren dentro del notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Ejercicio1\"></a>\n",
    "# Ejercicio 1: Teoría de la generalización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considere el conjunto de hipótesis $\\mathcal{H}$ dado por los rayos positivos o negativos, es decir,\n",
    "todas las hipótesis en R que devuelven +1 a la derecha de un punto a y -1 a la izquierda\n",
    "(rayos positivos), o que devuelven -1 a la derecha y +1 a la izquierda (rayos negativos), como se muestra en la figura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=\"figuras/rayos.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Ej1-Parte-a\"></a>\n",
    "### Ejercicio 1 - parte a) (XX puntos) \n",
    "Calcule la función de crecimiento $m_{\\mathcal{H}}(N)$ de este conjunto de hipótesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta:**   \n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Ej1-Parte-b\"></a>\n",
    "### Ejercicio 1 - parte b) (XX puntos) \n",
    "Calcule el menor punto de quiebre $k$ y la dimensión de Vapnik-Chervonenkis $d_{\\textrm{VC}}$ para la función de crecimiento calculada en la parte anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta:**   \n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Ej1-Parte-c\"></a>\n",
    "### Ejercicio 1 - parte c) (XX puntos) \n",
    "Escriba la cota polinómica para la función de crecimiento de la primera parte explícitamente como: i) un polinomio en $N$ (con todos los términos) y ii) como el monomio de mayor orden, usando el valor de $d_{\\textrm{VC}}$ de la parte anterior. Puede ser útil el comando de latex <i>binom</i> que permite generar: $\\binom{N}{i}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta:**   \n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Ej1-Parte-d\"></a>\n",
    "### Ejercicio 1 - parte d) (XX puntos) \n",
    "Considere la desigualdad de Vapnik-Chervonenkis \n",
    "$$ P[|E_{\\textrm{in}}(g) - E_{\\textrm{out}}(g)| > \\epsilon]  \\leq 4 m_{\\mathcal{H}}(2N) e^{-\\frac{1}{8} \\epsilon^2 N} \\quad \\quad \\epsilon > 0 $$\n",
    "Dado un nivel de tolerancia $\\delta = 4 m_{\\mathcal{H}}(2N) e^{-\\frac{1}{8} \\epsilon^2 N}$, escriba una cota para el error fuera de muestra $E_{\\textrm{out}}(g)$ que se cumpla con probabilidad $1-\\delta$, de la forma $E_{\\textrm{out}}(g) \\leq E_{\\textrm{in}}(g) + \\Omega(N, \\mathcal{H}, \\delta)$, dando explícitamente la expresión para $\\Omega$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta:**   \n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Ej1-Parte-e\"></a>\n",
    "### Ejercicio 1 - parte e) (XX puntos) \n",
    "Para un nivel de confianza del 90\\% y $N=1000$, indique cuál es la cota que puede ofrecer para el error que se comete por encima de $E_{\\textrm{in}}$, es decir, el valor que toma $\\Omega$ en este caso. Utilice el resultado de parte c) para acotar la función de crecimiento $m_{\\mathcal{H}}(N)$ en función de $N$ y $d_{\\textrm{VC}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta:**   \n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Ejercicio2\"></a>\n",
    "# Ejercicio 2: Regresión logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En un problema de dos clases, el modelo de regresión logística asume que la probabilidad a posteriori de pertenencia a la clase positiva puede ser escrita de la siguiente forma:\n",
    "\n",
    "$$\n",
    "P(y=1|\\mathbf{x}_n;\\mathbf{w})= \\theta \\left( \\mathbf{w}^T\\mathbf{x}_n \\right)= \\frac{1}{1+\\exp\\left(-\\left(\\mathbf{w}^T\\mathbf{x}_n\\right)\\right)}\n",
    "$$\n",
    "\n",
    "donde $\\mathbf{x_n}=\\left( 1, x_{n1},x_{n2},...,x_{nd}\\right)$ es el n-ésimo vector de característcas expresado en coordenadas homogéneas y $d$ es el número de característcas.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ej2 a)** Mostrar que $P(y=y_n|\\mathbf{x}_n;\\mathbf{w}) = \\frac{1}{1+\\exp\\left(-\\left(y_n \\mathbf{w}^T\\mathbf{x}_n\\right)\\right)} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta:**   \n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ej2 b)** Mostrar que la log-verosimilitud $l(\\mathbf{y}| \\mathbf{X};\\mathbf{w})$ en el modelo logístico se escribe como $$\n",
    " l(\\mathbf{y}| \\mathbf{X};\\mathbf{w}) = \\sum_{n=1}^{N} \\log \\left( \\theta(y_n \\mathbf{w}^T\\mathbf{x}_n) \\right)\n",
    "$$\n",
    "\n",
    "donde $\\mathbf{X}$ es una matriz de $N \\times (d+1)$ e $\\mathbf{y}$ es un vector que contiene las $N$ etiquetas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta:**   \n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ej2 c)** Mostrar que encontrar el $\\mathbf{w}$ que maximiza la log-verosimilitud es equivalente a encontrar el $\\mathbf{w}$ que minimiza la función de costo: \n",
    "\n",
    "$$\n",
    "E_{in}(\\mathbf{w}) = \\frac{1}{N}\\sum_{n=1}^N \\log \\left( 1 + \\exp \\left( -y_n \\mathbf{w}^T\\mathbf{x}_n \\right) \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta:**   \n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ej2 d)** Mostrar que $$\\nabla E_{in}(\\mathbf{w}) = \\frac{1}{N} \\sum_{n=1}^{N} -y_n \\mathbf{x}_n \\theta  \\left( - y_n \\mathbf{w}^T\\mathbf{x_n} \\right) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta:**   \n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Ejercicio3\"></a>\n",
    "# Ejercicio 3: Clasificación de dígitos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejercicio se trabajará con la base USPS de dígitos disponible en [kaggle](https://www.kaggle.com/bistaumanga/usps-dataset) que se utilizó en el práctico. El objetivo será separar el dígito uno de los restantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El ejercicio consta de 15 partes. Las partes indicadas con color rojo son puntos de control que pueden ser realizadas aún cuando alguna de las partes anteriores no haya sido completada. Para realizar dichas partes sin haber completado alguna anterior puede que sea necesario ejecutar todas las celdas anteriores.\n",
    "* [Extracción de características](#Extraccion)\n",
    "    * [Parte 1](#Parte1)\n",
    "* [División del conjunto en entrenamiento y test](#DivisionEntrenamientoTest)\n",
    "    * [<font color='red'> Parte 2 </font>](#Parte2)\n",
    "* [Normalización de características](#Normalizacion)\n",
    "    * [<font color='red'> Parte 3 </font>](#Parte3)\n",
    "* [Transformación de características](#TransformacionCaracteristicas)\n",
    "    * [<font color='red'> Parte 4 </font>](#Parte4),  [Parte 5](#Parte5)\n",
    "* [Regresión lineal para clasificación](#RegresionLineal) \n",
    "    * [<font color='red'> Parte 6 </font>](#Parte6),  [<font color='red'> Parte 7 </font>](#Parte7), [Parte 8](#Parte8), [Parte 9](#Parte9), [Parte 10](#Parte10)\n",
    "* [Validación cruzada](#ValidacionCruzada)\n",
    "    * [<font color='red'> Parte 11 </font>](#Parte11) y [Parte 12](#Parte12)\n",
    "* [Evaluación con conjunto de test](#ConjuntoTest)\n",
    "    * [Parte 13](#Parte13)\n",
    "* [Preguntas finales](#Preguntas)\n",
    "    * [<font color='red'> Parte 14 </font>](#Parte14) y [<font color='red'> Parte 15 </font>](#Parte14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A continuación se cargan los datos y se muestra una imagen de cada dígito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='usps/usps.h5'\n",
    "\n",
    "with h5py.File(path, 'r') as hf:\n",
    "        train = hf.get('train')\n",
    "        X_train = train.get('data')[:]\n",
    "        y_train = train.get('target')[:]\n",
    "        test = hf.get('test')\n",
    "        X_test = test.get('data')[:]\n",
    "        y_test = test.get('target')[:]\n",
    "\n",
    "# Se combinan todos los datos en un solo conjunto\n",
    "X = np.vstack((X_train,X_test))\n",
    "y = np.hstack((y_train,y_test)).T\n",
    "del X_train, y_train, X_test, y_test\n",
    "\n",
    "# Se deberían ver 2 × 5 subfiguras con una imagen  \n",
    "# representativa de cada dígito\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=5, sharex=True, sharey=True)\n",
    "ax = ax.flatten()\n",
    "for i in range(10):\n",
    "    img = X[y == i][0].reshape(16, 16)\n",
    "    ax[i].imshow(img, cmap='gray')\n",
    "    ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Extraccion\"></a>\n",
    "## Extracción de características"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En vez de trabajar con los valores de los píxeles como características se generará una representación de los dígitos mucho más compacta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Parte1\"></a>\n",
    "### Parte 1 (XX Puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completar el código de la función `caracterizar_digitos(digitos)`, la misma genera una representación de los dígitos utilizando solamente dos características. \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "intensidad &= \\frac{1}{256}\\sum_{m=0}^{15}\\sum_{n=0}^{15}I(m,n)  \\\\\n",
    "simetria &= 1 - \\frac{1}{256}\\sum_{m=0}^{15}\\sum_{n=0}^{15} \\frac{ \\vert I(m,n)- I(m,15 - n) \\vert + \\vert I(m,n)- I(15-m, n)\\vert}{2} \\\\\n",
    "         &= \\frac{\\text{simetria horizontal}+\\text{simetria vertical}}{2}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caracterizar_digitos(digitos):\n",
    "    '''\n",
    "    Genera las características que se utilizarán para clasificar los dígitos\n",
    "    Entrada:\n",
    "        digitos: matriz de Nxd que contiene N dígitos\n",
    "    Salida:\n",
    "        features: matriz de Nx2 con las característcas calculadas. En principio se \n",
    "                  sugiere calcular la intensidad promedio y una medida de simetría, \n",
    "                  pero podría calcularse alguna otra medida.\n",
    "    '''\n",
    "    N = digitos.shape[0]\n",
    "    features = np.zeros((N,2))  # vector que almacena las características generadas\n",
    "    \n",
    "    #######################################################\n",
    "    ######## EMPIEZA ESPACIO PARA COMPLETAR CODIGO ########\n",
    "    #######################################################\n",
    "    \n",
    "    # se calcula la intensidad promedio\n",
    "    # intensidad =\n",
    "    \n",
    "    \n",
    "    # se calcula la simetría. Previo al cálculo de las simetrías puede ser útil np.reshape() \n",
    "    # para transformar el vector de entrada de tamaño Nx256 en uno de Nx16x16 \n",
    "    \n",
    "    # simetría = (simetria_horizontal + simetria_vertical)/2\n",
    "    \n",
    "    \n",
    "    #features[:,0] = ...\n",
    "    #features[:,1] = ...\n",
    "    \n",
    "    #######################################################\n",
    "    ######## TERMINA ESPACIO PARA COMPLETAR CODIGO ########\n",
    "    #######################################################\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se calculan las características para los dígitos y se las guarda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_estudiante = caracterizar_digitos(X)\n",
    "print('Se calcularon las características de %d dígitos' % features_estudiante.shape[0] )\n",
    "\n",
    "# Se guardan las características calculadas por el estudiante\n",
    "np.save('caracteristicas_estudiante', features_estudiante)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se comparan las características calculadas con las características precalculadas por los docentes. Si la implementación de `caracterizar_digitos()` es correcta la ejecución de la celda muestra el valor True. De aquí en más se trabajará con las características calculadas por los docentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se levantan las características calculadas por los docentes \n",
    "features = np.load('caracteristicas_docentes.npy')\n",
    "np.allclose(features_estudiante, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"DivisionEntrenamientoTest\"></a>\n",
    "## División entre conjunto de entrenamiento y test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al conjunto de datos disponibles se lo dividirá en un conjunto de entrenamiento y uno de test. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Parte2\"></a>\n",
    "### Parte 2 (XX Puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completar la siguiente celda de forma que se seleccionen aleatoriamente 300 dígitos para el conjunto de entrenamiento. Los demás dígitos formarán parte del conjunto de test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_random = 300      # se van a elegir aleatoriamente 300 puntos para entrenamiento\n",
    "N = X.shape[0]     # número de puntos totales\n",
    "np.random.seed(42) # 42    \n",
    " \n",
    "# Se dividen aleatoriamente los índices de cada conjunto (entrenamiento y test)\n",
    "indices = np.random.permutation(N)\n",
    "indices_train = indices[:N_random]\n",
    "indices_test =  indices[N_random:]\n",
    "\n",
    "#######################################################\n",
    "######## EMPIEZA ESPACIO PARA COMPLETAR CODIGO ########\n",
    "#######################################################   \n",
    "\n",
    "# Se seleccionan las características que se utilizarán en el conjunto de entrenamiento\n",
    "# features_train =\n",
    "\n",
    "# Se seleccionan las correspondientes etiquetas para el conjunto de entrenamiento\n",
    "# y_train =\n",
    "\n",
    "# Se seleccionan las características que se utilizarán en el conjunto de test\n",
    "# features_test =\n",
    "\n",
    "# Se seleccionan las etiquetas que se utilizarán en el conjunto de test\n",
    "# y_test =\n",
    "\n",
    "#######################################################\n",
    "######## TERMINA ESPACIO PARA COMPLETAR CODIGO ########\n",
    "#######################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Normalizacion\"></a>\n",
    "## Normalización de características"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se plantea realizar una normalización de las características del conjunto de entrenamiento. Esto quiere decir que para cada una de las características se deberá encontrar un factor de escala y una traslación de forma tal que el mínimo valor que toma esa característica sea -1 y el máximo valor +1. La transformación es de la forma:\n",
    "\n",
    "$$\n",
    "f_n= \\alpha (f + \\beta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Parte3\"></a>\n",
    "### Parte 3 (XX Puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizar los puntos del conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traslación de la primera característica\n",
    "# beta1 = \n",
    "\n",
    "# factor de re-escalado de la primera característica\n",
    "# alpha1 = \n",
    "\n",
    "# traslación de la segunda característica\n",
    "# beta2 = \n",
    "\n",
    "# factor de re-escalado de la segunda característica\n",
    "# alpha2 = \n",
    "\n",
    "\n",
    "# caracteristicas de entrenamiento normalizadas\n",
    "# features_train_n_estudiante = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente celda verifica que las características fueron correctamente normalizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min0, min1 = np.min(features_train_n_estudiante, axis=0)\n",
    "max0, max1 = np.max(features_train_n_estudiante, axis=0)\n",
    "print('El rango de la característica cero es: [%.02f, %.02f]' % (min0, max0))\n",
    "print('El rango de la característica uno es: [%.02f, %.02f]' % (min1, max1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se guardan las características calculadas y se levantan las características normalizadas precalculadas por los docentes. Si ambas coinciden la ejecución de la celda muestra el valor True. De aquí en más se trabajará con las precalculadas por los docentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se guardan las características normalizadas calculadas por el estudiante\n",
    "np.save('caracteristicas_train_normalizadas_estudiante', features_train_n_estudiante)\n",
    "\n",
    "# Se guardan las etiquetas de entrenamiento calculadas por el estudiante\n",
    "np.save('y_train_estudiante', y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se levantan las características normalizadas precalculadas por los docentes\n",
    "features_train_n = np.load('caracteristicas_train_normalizadas_docentes.npy')\n",
    "\n",
    "# Se levantan las etiquetas de entrenamiento precalculadas por los docentes\n",
    "y_train = np.load('y_train_docentes.npy')\n",
    "\n",
    "np.allclose(features_train_n_estudiante, features_train_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generar problema de dos clases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función `generar_problema_dos_clases()` es la encargada de generar, a partir de las características y etiquetas originales, un conjunto de datos listos para ser utilizados en un problema de clasificación de dos clases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_problema_dos_clases(X, y, clase1, clase2):\n",
    "    '''\n",
    "    Entrada: \n",
    "        X: matriz de dígitos\n",
    "        y: etiquetas asociadas a los dígitos\n",
    "        clase1: lista con los dígitos a los que se le asignará la clase 1\n",
    "        clase2: lista con los dígitos a los que se le asignará la clase -1\n",
    "    Salida:\n",
    "        Xb: matriz que contiene únicamente las características de los dígitos \n",
    "            clase1 y clase 2\n",
    "        yb: etiquetas asignadas a los dígitos clase1 y clase2 (1 o -1)\n",
    "    '''\n",
    "    \n",
    "    indicesClase1 = [ etiqueta in clase1 for etiqueta in y ] \n",
    "    indicesClase2 = [ etiqueta in clase2 for etiqueta in y ]\n",
    "\n",
    "    clase1 = X[indicesClase1]\n",
    "    clase2 = X[indicesClase2]\n",
    "\n",
    "    Xb = np.vstack((clase1,clase2))\n",
    "    yb = np.ones(len(Xb),dtype=int)\n",
    "    yb[len(clase1):] *= -1\n",
    "\n",
    "    return Xb, yb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este problema una de las clases será el dígito 1 (se le asignará la etiqueta 1) mientras que la otra clase estará compuesta por los restantes dígitos (se les asignará la etiqueta -1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clase1 = [1]\n",
    "clase2 = [0,2,3,4,5,6,7,8,9]\n",
    "Xb_train, yb_train = generar_problema_dos_clases(features_train_n, y_train, clase1, clase2)\n",
    "\n",
    "# Se verifica que las dimensiones sean correctas\n",
    "assert ( np.sum( [y in clase1 for y in y_train] ) + np.sum( [y in clase2 for y in y_train] )  == len(yb_train) ), \\\n",
    "        'La dimensión del vector de etiquetas de entrenamiento generado no es correcta'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"TransformacionCaracteristicas\"></a>\n",
    "## Transformación de características"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para resolver el problema se propone realizar una transformación de las características a un espacio de mayor dimensión. Para ello se consideran dos posibilidades: \n",
    "\n",
    "$\\textbf{Transformación polinómica canónica:}$\n",
    "\n",
    "La transformación polinómica de dos características $(x_1, x_2)$ se define como:\n",
    "\n",
    "$$\n",
    "    (x_1, x_2) \\rightarrow (1, x_1, x_2, x_1^2, x_1x_2, x_2^2, x_1^3, x_1^2x_2,...)\n",
    "$$\n",
    "\n",
    "$\\textbf{Transformación de Legendre:}$\n",
    "\n",
    "Los polinomios de Legendre son una familia de polinomios ortogonales muy utilizados en problemas de regresión. De manera análoga a la transformación canónica, la transformación en polinomios de Legendre de define como: \n",
    "\n",
    "$$\n",
    "    (x_1, x_2) \\rightarrow (1, L_1(x_1), L_1(x_2), L_2(x_1), L_1(x_1)L_1(x_2), L_2(x_2), L_3(x_1), L_2(x_1)L_1(x_2),...)\n",
    "$$\n",
    "\n",
    "donde en cada característica se reemplaza $x_i^k$ por $L_k(x_i)$ siendo $L_k(\\cdot)$ el polinomio de Legendre de orden $k$.\n",
    "\n",
    "Los primeros dos polinomios son $L_0(x)=1$ y $L_1(x)=x$. Los polinomios de mayor orden se definen mediante la recursión:\n",
    "\n",
    "$$\n",
    "L_k(x)=\\frac{2k-1}{k}xL_{k-1}(x)-\\frac{k-1}{k}L_{k-2}(x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Parte4\"></a>\n",
    "### Parte 4 (XX puntos) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementar la función `evaluar_Legendre()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_Legendre(x_, k):\n",
    "    '''\n",
    "    Evalúa el polinomio de Legendre de orden k en los puntos del vector x_\n",
    "    Entrada:\n",
    "        x_: vector que contiene los puntos a ser evaluados\n",
    "        k:  orden del polinomio de Legendre a evaluar en los valores de x_\n",
    "    Salida:\n",
    "        Lk: vector que contiene los valores de los polinomios de Legendre de orden k evaluados en x_\n",
    "    '''\n",
    "    \n",
    "    #######################################################\n",
    "    ######## EMPIEZA ESPACIO PARA COMPLETAR CODIGO ########  \n",
    "    #######################################################   \n",
    "\n",
    "\n",
    "        \n",
    "    #######################################################\n",
    "    ######## TERMINA ESPACIO PARA COMPLETAR CODIGO ########  \n",
    "    #######################################################   \n",
    "\n",
    "    \n",
    "    return Lk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función `transformacion_polinomica()` realiza una transformación polinómica de orden $n$. Permite elegir el tipo de transformación y el orden de la misma. Dicha función ya ha sido implementada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformacion_polinomica(features, tipo_transformacion='Canonica', orden_transformacion = 8):\n",
    "    '''\n",
    "    features: matriz de tamaño de Nx2 que contiene las características a transformar\n",
    "    tipo_transformacion:  tipo de transformación a aplicar.\n",
    "                         'Canonica': Realiza una transformación polinómica canónica\n",
    "                         'Legendre': Realiza una transformación de Legendre\n",
    "    orden_transformacion: orden de la transformación a aplicar\n",
    "    '''\n",
    "    \n",
    "    # Número de puntos\n",
    "    N = features.shape[0]\n",
    "    \n",
    "    # Lista que contiene la cantidad de dimensiones para cada orden. \n",
    "    # Ej: para orden 0 la dimensión es 1. Una transformación de orden 1 agrega dos dimensiones más,\n",
    "    # una de orden 2 agrega 3 más, etc.\n",
    "    dimensiones_por_orden = [k+1 for k in range(orden_transformacion+1)]\n",
    "    \n",
    "    # se transforma el tipo de datos de lista a numpy.array\n",
    "    dimensiones_por_orden = np.asarray(dimensiones_por_orden)\n",
    "    \n",
    "    # La dimensión total de la transformación es igual a la suma de dimensiones agregadas en cada orden\n",
    "    D = dimensiones_por_orden.sum()\n",
    "    \n",
    "    # Se inicializa la matriz de características en el espacio transformado a cero\n",
    "    features_T = np.zeros((N,D))\n",
    "    \n",
    "    d=0\n",
    "    for k in range(orden_transformacion + 1):\n",
    "        \n",
    "        # cantidad de dimensiones que aporta el orden x \n",
    "        dim_orden_k = dimensiones_por_orden[k]\n",
    "       \n",
    "        for l in range(dim_orden_k):\n",
    "            \n",
    "            if tipo == 'Legendre': \n",
    "                features_T[:,d] = evaluar_Legendre(features[:,0], l)*evaluar_Legendre(features[:,1], (k-l))\n",
    "            elif tipo == 'Canonica':\n",
    "                features_T[:,d]=features[:,0]**l * features[:,1]**(k-l)\n",
    "            d=d+1\n",
    "    \n",
    "    return features_T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Parte5\"></a>\n",
    "### Parte 5 (XX puntos) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para resolver el problema se decide realizar una **transformación polinómica** de **orden 8** de las características. Elegir el tipo de transformación que considere adecuado  de forma tal que el conjunto de hipótesis tenga la mayor capacidad expresiva que sea posible con dicho orden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tipo = 'Canonico' # Se debe elegir 'Canonico' o 'Legendre' \n",
    "orden = 8\n",
    "Zb_train_estudiante  = transformacion_polinomica(Xb_train, tipo_transformacion=tipo, orden_transformacion=orden)\n",
    "print('El número de características en el espacio transformado es %d' % Zb_train_estudiante.shape[1])\n",
    "\n",
    "if tipo == 'Canonico':\n",
    "    # Se guardan las características caculadas por los estudiantes\n",
    "    np.save('Zb_train_canonico_estudiante', Zb_train_estudiante)\n",
    "elif tipo == 'Legendre':\n",
    "    # Se guardan las características caculadas por los estudiantes\n",
    "    np.save('Zb_train_legendre_estudiante', Zb_train_estudiante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tipo == 'Canonico':\n",
    "    # Se levantan las características caculadas por los docentes\n",
    "    Zb_train = np.load('Zb_train_canonico_docentes.npy')\n",
    "elif tipo == 'Legendre':\n",
    "    # Se levantan las características caculadas por los docentes\n",
    "    Zb_train = np.load('Zb_train_legendre_docentes.npy')\n",
    "    \n",
    "# Se comparan las características calculadas por los docentes con las calculadas por el estudiante\n",
    "np.allclose(Zb_train, Zb_train_estudiante)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"RegresionLineal\"></a>\n",
    "## Regresión lineal para clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se abordará este problema como uno de regresión lineal con $\\textit{valores objetivos} \\pm 1$. Los parámetros óptimos $\\mathbf{w}_{\\textrm{reg}}$ del modelo lineal se obtendrán mediante la siguiente ecuación:   \n",
    "\n",
    "$\\mathbf{w}_{\\textrm{reg}} = (\\mathbf{Z}^{\\intercal}\\mathbf{Z} + \\lambda \\mathbf{I})^{-1} \\mathbf{Z}^{\\intercal} \\mathbf{y}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Parte6\"></a>\n",
    "### Parte 6 (XX puntos) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indique cuál es la optimización que da lugar a la solución planteada para $\\mathbf{w}_{reg}$. En particular comente el rol que cumple $\\lambda$ en dicha optimización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta:**   \n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Parte7\"></a>\n",
    "### Parte 7 (XX puntos) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método `regresion_Ridge()` obtiene el vector $\\mathbf{w}_{\\textrm{reg}}$ a partir de la solución encontrada en la parte anterior. Implementarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regresion_Ridge(Z, y, reg = 0, regularizar_bias=False):\n",
    "    \n",
    "    '''\n",
    "    Implementa la solución cerrada de la regresión de Ridge. En esta variante se\n",
    "    permite elegir si se desea regularizar el bias (coeficiente w_0) o no.\n",
    "    Entrada:\n",
    "        Z: matríz de tamaño Nx(d+1) \n",
    "        y: valores objetivo\n",
    "        reg: coeficiente que multiplica el término de regularización\n",
    "        regularizar_bias: variable booleana que indica si se regulariza el término\n",
    "                        de bias o no.\n",
    "    Salida:\n",
    "        w_reg: parámetros encontrados mediante la regularización de Ridge\n",
    "    '''\n",
    "\n",
    "    # Si no se regulariza el coeficiente w_0 se pone el elemento [0,0]\n",
    "    # de la matríz identidad a cero      \n",
    "    reg_matrix = np.identity(Z.shape[1])\n",
    "    if not regularizar_bias:\n",
    "        reg_matrix[0,0]=0\n",
    "    \n",
    "    ########################################################################\n",
    "    ############# EMPIEZA ESPACIO PARA COMPLETAR CÓDIGO  ###################\n",
    "    ########################################################################\n",
    "    \n",
    "    # w_reg =\n",
    "     \n",
    "    ########################################################################\n",
    "    ############# TERMINA ESPACIO PARA COMPLETAR CÓDIGO  ###################\n",
    "    ########################################################################\n",
    "    \n",
    "    return w_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión lineal sin regularización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Parte8\"></a>\n",
    "### Parte 8 (XX puntos) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encontrar el vector de pesos y el error de clasificación con el conjunto de entrenamiento sin utilizar ningún tipo de regularización. Se entiende por error de clasificación al porcentaje de muestras mal clasificadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "############# EMPIEZA ESPACIO PARA COMPLETAR CÓDIGO  ###################\n",
    "########################################################################\n",
    "\n",
    "# w_ls_0 =\n",
    "\n",
    "# Error de clasificación con el conjunto de entrenamiento\n",
    "# error_ls_0 =\n",
    "\n",
    "########################################################################\n",
    "############# TERMINA ESPACIO PARA COMPLETAR CÓDIGO  ###################\n",
    "########################################################################\n",
    "print('Error de clasificación utilizando regresión lineal (espacio transformado) = %f' % error_ls_0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización de las fronteras de decisión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método `visualizar_frontera_decision()` muestra la frontera de decisión encontrada. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizar_frontera_decision(X, y, w, tipo, orden):\n",
    "    '''\n",
    "    Entrada:\n",
    "        X: matriz de Nx2 que contiene los puntos en el espacio original\n",
    "        y: etiquetas de los puntos\n",
    "        w: vector del modelo lineal en el espacio transormado que contiene los parámetros encontrados\n",
    "        orden: orden de la transformación polinómica\n",
    "    '''\n",
    "\n",
    "    # Se construye una grilla de 50x50 en el dominio de los datos\n",
    "    xs = np.linspace( X[:,0].min(), X[:,0].max())\n",
    "    ys = np.linspace( X[:,1].min(), X[:,1].max())\n",
    "\n",
    "    XX, YY = np.meshgrid( xs, ys ) \n",
    "    ZZ = np.zeros_like(XX)\n",
    "    \n",
    "    # se transforman los puntos de la grilla\n",
    "    pts_grilla = np.vstack( (XX.ravel(),YY.ravel()) ).T\n",
    "    Z = transformacion_polinomica( pts_grilla, tipo_transformacion = tipo, orden_transformacion=orden)\n",
    "    \n",
    "    # los puntos transformados son proyectados utilizando el w\n",
    "    ZZ = Z @ w\n",
    "    ZZ = ZZ.reshape(XX.shape)#\n",
    "    \n",
    "    # se grafica la frontera de decisión, es decir, la línea de nivel 0  \n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.contour(XX, YY, ZZ, [0], colors='k', linewidths=0.7)\n",
    "    # a los efectos de la visualización se multiplica por menos uno el signo para que el colormap \n",
    "    # le asigne color azul a los unos y rojo a los demás dígitos.\n",
    "    plt.contourf(XX, YY, -np.sign(ZZ), alpha=0.25, cmap='bwr')\n",
    "    plt.scatter(X[:,0][y==1],X[:,1][y==1], s=40, color='b', marker='o', \n",
    "                label='etiqueta -1')\n",
    "    plt.scatter(X[:,0][y==-1],X[:,1][y==-1], s=40, color='r', marker='x', \n",
    "                label='etiqueta 1')\n",
    "    plt.title('Frontera de decision obtenida mediante transformación no lineal de datos')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutar la siguiente celda y corroborar visualmente que la frontera de decisión mostrada es coherente con el resultado obtenido con el conjunto de entrenamiento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se grafica el resultado del entrenamiento\n",
    "visualizar_frontera_decision(Xb_train,yb_train, w_ls_0, tipo, orden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión lineal con regularización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Parte9\"></a>\n",
    "### Parte 9 (XX puntos) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encontrar el vector de pesos $\\mathbf{w}_{ls\\_2}$ y el correspondiente error de clasificación utilizando el conjunto de entrenamiento cuando el factor de regularización es $\\lambda=2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "############# EMPIEZA ESPACIO PARA COMPLETAR CÓDIGO  ###################\n",
    "########################################################################\n",
    "\n",
    "# w_ls_2 =\n",
    "\n",
    "# Error de clasificación con el conjunto de entrenamiento\n",
    "# error_ls_2 =\n",
    "\n",
    "########################################################################\n",
    "############# TERMINA ESPACIO PARA COMPLETAR CÓDIGO  ###################\n",
    "########################################################################\n",
    "print('Error de clasificación utilizando regresión lineal (espacio transformado) = %f' % error_ls_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se grafica el resultado del entrenamiento  \n",
    "visualizar_frontera_decision(Xb_train, yb_train, w_ls_2, tipo, orden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Parte10\"></a>\n",
    "### Parte 10 (XX puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare los puntos de funcionamiento obtenidos con factores de regularización $\\lambda=0$ y $\\lambda=2$ en términos del grado de ajuste a los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ValidacionCruzada\"></a>\n",
    "## Validación cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta parte se buscará encontrar el factor de regularización óptimo $\\lambda_{opt}$ mediante el procedimiento de validación cruzada. La estimación de $E_{cv}$ se realizará utilizando la fórmula cerrada:\n",
    "\n",
    "$$\n",
    "E_{cv}(\\lambda)=\\frac{1}{N}\\sum_{n=1}^N \\left( \\frac {\\hat{y}_n - y_n} {1 - H_{nn}(\\lambda)}  \\right)^2\n",
    "$$\n",
    "\n",
    "donde $H(\\lambda)=Z(Z^TZ + \\lambda I)^{-1}Z^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Parte11\"></a>\n",
    "### Parte 11 (XX puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completar la implementación del método `validacion_cruzada_analitica()` y utilizarlo para encontrar el factor de regularización óptimo $\\lambda^*$ y el error de validación cruzada correspondiente a dicho valor óptimo $E_{cv}(\\lambda^*$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validacion_cruzada_analitica(Z, y, lambdas, regularizar_bias=False):\n",
    "    \n",
    "    '''\n",
    "    Método que calcula el vector E_cv para los valores de lambda indicados en\n",
    "    el vector lambdas\n",
    "    Entrada:\n",
    "        Z: matriz de tamaño Nx(d+1) que contiene en cada fila un vector de \n",
    "           características expresado en coordenadas homogéneas\n",
    "        y: vector de etiquetas\n",
    "        lambdas: vector que contiene los factores de regularización a considerar\n",
    "    Salida:\n",
    "        E_cv: vector que contiene en cada componente el resultado de aplicar \n",
    "              validación cruzada con el correspondiente factor de regularización \n",
    "    '''\n",
    "    \n",
    "    # Se define el vector que guardará los resultados de la validación cruzada\n",
    "    E_cv = np.empty(len(lambdas))\n",
    "    \n",
    "    reg_matrix = np.identity(Z.shape[1])\n",
    "    if not regularizar_bias:\n",
    "        reg_matrix[0,0]=0\n",
    "        \n",
    "    ########################################################################\n",
    "    ############# EMPIEZA ESPACIO PARA COMPLETAR CÓDIGO  ###################\n",
    "    ########################################################################\n",
    "    \n",
    "    # puede ser útil el método diag() de numpy\n",
    "    \n",
    "    for l, reg in enumerate(lambdas):\n",
    "        H = Z @ np.linalg.inv( Z.T @  Z  + reg*reg_matrix ) @ Z.T\n",
    "        y_pred = H @ y\n",
    "        E_cv[l] = np.mean( ( (y_pred - y)/(1 - np.diag(H)) )**2 )\n",
    "    \n",
    "    ########################################################################\n",
    "    ############# TERMINA ESPACIO PARA COMPLETAR CÓDIGO  ###################\n",
    "    ########################################################################\n",
    "\n",
    "    return E_cv\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se genera la grilla con los valores de regularización a probar\n",
    "max_lambda = 10; step=0.1\n",
    "lambdas = np.arange(step, max_lambda, step)\n",
    "\n",
    "########################################################################\n",
    "############# EMPIEZA ESPACIO PARA COMPLETAR CÓDIGO  ###################\n",
    "########################################################################\n",
    "\n",
    "# E_cv = \n",
    "\n",
    "# lambda_optimo = \n",
    "\n",
    "# E_cv_optimo = \n",
    "\n",
    "########################################################################\n",
    "############# TERMINA ESPACIO PARA COMPLETAR CÓDIGO  ###################\n",
    "########################################################################\n",
    "\n",
    "print('El lambda óptimo es: %f con un error en validación curzada de %f' % (lambda_optimo, E_cv_optimo))\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "#plt.plot(lambdas,  E_cv_ls, 'b.', label='Espacio original')\n",
    "plt.plot(lambdas,  E_cv,'r.', label='Espacio transformado')\n",
    "plt.xlabel('factor de regularización')\n",
    "plt.ylabel('error')\n",
    "plt.title('Error de validación cruzada')\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Modelo con el factor de regularización óptimo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Parte12\"></a>\n",
    "### Parte 12 (XX puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estime el vector de pesos con el factor de regularización óptimo y el error de clasificación con el conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "############# EMPIEZA ESPACIO PARA COMPLETAR CÓDIGO  ###################\n",
    "########################################################################\n",
    "\n",
    "# Se estima el vector de pesos óptimo\n",
    "# w_ls_reg = \n",
    "\n",
    "\n",
    "# Se estima el error con el conjunto de entrenamiento\n",
    "# error_ls_reg = \n",
    "\n",
    "########################################################################\n",
    "############# TERMINA ESPACIO PARA COMPLETAR CÓDIGO  ###################\n",
    "########################################################################\n",
    "print('Error de clasificación utilizando regresión lineal (espacio transformado) = %f' % error_ls_reg )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizar_frontera_decision(Xb_train, yb_train, w_ls_reg, tipo, orden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ConjuntoTest\"></a>\n",
    "## Error con el conjunto de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se estimará el error $E_{out}$ a partir del error de clasificación con el conjunto de test $E_{test}(\\mathbf{w}_{reg}(\\lambda))$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Parte13\"></a>\n",
    "### Parte 13 (XX puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completar la siguiente celda para estimar el error de clasificación $E_{out}$ con el conjunto de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "############# EMPIEZA ESPACIO PARA COMPLETAR CÓDIGO  ###################\n",
    "########################################################################\n",
    "\n",
    "\n",
    "# se normalizan las características del conjunto de test\n",
    "# features_test_n = \n",
    "\n",
    "# se ajustan las etiquetas para el problema de dos clases que se quiere resolver\n",
    "\n",
    "# se realiza la transformación no lineal de características\n",
    "\n",
    "# yb_pred_test =\n",
    "\n",
    "# E_out = \n",
    "\n",
    "print('El error de clasificación con el conjunto de test es %f' % E_out)\n",
    "########################################################################\n",
    "############# TERMINA ESPACIO PARA COMPLETAR CÓDIGO  ###################\n",
    "########################################################################\n",
    "\n",
    "# Se grafica el resultado con el conjunto de test  \n",
    "visualizar_frontera_decision(Xb_test, yb_test, w_ls_reg, tipo, orden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Preguntas\"></a>\n",
    "### Preguntas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Parte14\"></a>\n",
    "### Parte 14 (XX puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El orden de la transformación utilizado parece excesivo teniendo en cuenta la cantidad de datos de entrenamiento. Fundamente esta afirmación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta:**\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Parte15\"></a>\n",
    "### Parte 15 (XX puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la normalización realizada hay varios puntos del conjunto de test que quedan fuera del rango [-1,1]. Se podrían ajustar los parámetros de normalización para evitarlo. Argumente por qué esto no es una buena idea. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta:**   \n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
