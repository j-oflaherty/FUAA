{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> FUNDAMENTOS DE APRENDIZAJE AUTOMÁTICO <br> Y RECONOCIMIENTO DE PATRONES</center>\n",
    "## <center> 2do parcial, 2019</center>           \n",
    "\n",
    "La duración del parcial es de 3 horas. El parcial consta de 3 ejercicios, cuya suma total es de 100 puntos. El parcial es sin material y no está permitido acceder a Internet. Ante cualquier duda comuníquese con los docentes. \n",
    "\n",
    "Este notebook corresponde al ejercicio 1. Hay un notebook por ejercicio planteado.\n",
    "\n",
    "* [Ejercicio 1 - Redes Neuronales](#Ejercicio1) (35 puntos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se importan las bibliotecas que se utilizarán\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Ejercicio1\"></a>\n",
    "## Ejercicio 1: Completar la implementación de una red neuronal de dos capas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funciones auxiliares (Ejecutar y seguir)\n",
    "def error_relativo(x, y):\n",
    "    ''' devuelve el error relativo'''\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))\n",
    "\n",
    "def calcular_gradiente_numerico_array(f, x, df, h=1e-5):\n",
    "    '''\n",
    "    Evalúa el gradiente numérico para una función que acepta un arreglo numpy y\n",
    "    devuelve un arreglo numpy.\n",
    "    '''\n",
    "    grad = np.zeros_like(x)\n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "        ix = it.multi_index\n",
    "\n",
    "        oldval = x[ix]\n",
    "        x[ix] = oldval + h\n",
    "        pos = f(x).copy()\n",
    "        x[ix] = oldval - h\n",
    "        neg = f(x).copy()\n",
    "        x[ix] = oldval\n",
    "\n",
    "        grad[ix] = np.sum((pos - neg) * df) / (2 * h)\n",
    "        it.iternext()\n",
    "    return grad\n",
    "\n",
    "\n",
    "def calcular_gradiente_numerico(f, x, verbose=True, h=0.00001):\n",
    "    '''\n",
    "    Evalúa el gradiente numérico de f en x\n",
    "    - f es una función que recibe un solo argumente\n",
    "    - x es el punto (numpy array) en que se evalúa el gradiente\n",
    "    '''\n",
    "    \n",
    "    # se inicializa el gradiente \n",
    "    grad = np.zeros_like(x)\n",
    "    # se define un iterador sobre todos los elementos de x\n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "\n",
    "        # se evalúa la función en x+h\n",
    "        ix = it.multi_index\n",
    "        oldval = x[ix]\n",
    "        x[ix] = oldval + h # se suma h al valor original de x\n",
    "        fxph = f(x) # se evalúa f(x + h)\n",
    "        x[ix] = oldval - h\n",
    "        fxmh = f(x) # se evalúa f(x - h)\n",
    "        x[ix] = oldval # se restaura el valor original de x\n",
    "\n",
    "        # se calcula la derivada parcial con la fórmula centrada\n",
    "        grad[ix] = (fxph - fxmh) / (2 * h) \n",
    "        if verbose:\n",
    "            print(ix, grad[ix])\n",
    "        it.iternext() # step to next dimension\n",
    "\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción del ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejercicio se implementarán algunos de los bloques constitutivos de una red neuronal de **tres capas**. El diagrama muestra el diagrama de bloques para la red de dos capas implementada en el práctico. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/diagrama_de_bloques.png\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se describen los bloques:\n",
    "- **Inicializar parámetros:** Inicializa los parámentros de la red. A los pesos de la capa $l$ de la red les llamaremos $W_l$, $b_l$ con $l=1,2,3$. \n",
    "- **Propagación hacia adelante:** La *propagación hacia adelante*  o *forward propagation* consiste en estimar la salida de la red a partir de la entrada. Cada nodo o capa de la red tiene un método *forward* asociado. Se proveen las implementaciones de los métodos forward asociados a los siguientes bloques:\n",
    "        - Afin\n",
    "        - Activación \n",
    "        - Afin --> Activación\n",
    "        \n",
    "- **Loss:** Calcula el valor de la función de costo a optimizar. Se implementarán dos funciones de costo:\n",
    "        - Entropía cruzada\n",
    "        - Entropía cruzada regularizada\n",
    "- **Propagación hacia atrás:** Durante la *propagación hacia atrás* o *backpropagation* se calculan los gradientes necesarios para actualizar los parámetros de la red. Se implementarán métodos *backward* para los siguientes bloques:\n",
    "        - Afin\n",
    "        - Activación \n",
    "        - Afin --> Activación\n",
    "- **Update:** Es el boque encargado de actualizar los parámetros. Para ello utiliza los gradientes calculados durante la *propagación hacia atrás* y un método de optimización. Se utilizará *descenso por gradiente* como método de optimización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Bloque de Inicialización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se implementará el bloque de inicialización para el caso de una red neuronal de **tres capas** con la siguiente estructura:    \n",
    "  Afin --> Activación 1 --> Afin --> Activacion 2 --> Afin --> Activación 3       \n",
    "\n",
    "### Parte a) \n",
    "Completar la implementación de `inicializar_pesos()`. Los pesos $W_l$ serán inicializados en valores aleatorios con distribución gaussiana de desviación estandar $\\sigma_l=1/\\sqrt{d_{l-1}}$, siendo $d_{l-1}$ el número de nodos de la capa $l-1$. Por ejemplo, para la primera capa $l=1$, la cantidad de nodos $d_{l-1}=d_0$ corresponde a la dimensión del vector de características. Los pesos correspondientes a términos de *bias* se inicializarán a cero. \n",
    "\n",
    "**Nota:** No necesario realizar una implementación genérica. Alcanza con que funcione para una red de tres capas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inicializar_pesos(dims, semilla=1):\n",
    "    \"\"\"\n",
    "    Entrada:\n",
    "        dims: lista que contiene el número de nodos de cada una de las capas. El primer elemento\n",
    "              corresponde al tamaño del vector de características y el último a la cantidad de \n",
    "              nodos en la última capa oculta.\n",
    "        semilla: semilla a utilizar para generar los valores aleatorios\n",
    "    \n",
    "    Salida:\n",
    "        parametros: diccionario de python que contiene los parámetros inicializados \n",
    "                    parametros['W' + str(l)] = ... \n",
    "                    parametros['b' + str(l)] = ...\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(semilla)\n",
    "    \n",
    "    ####################################################################################\n",
    "    ###########  EMPIEZA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "    # Sugerencia: puede ser útil utilizar np.random.randn() y ajustar la desviación estándar\n",
    "    W1 = (1/np.sqrt(dims[0])) * np.random.randn(dims[0], dims[1])\n",
    "    b1 = 0\n",
    "    W2 = (1/np.sqrt(dims[1])) * np.random.randn(dims[1], dims[2])\n",
    "    b2 = 0\n",
    "    W3 = (1/np.sqrt(dims[2])) * np.random.randn(dims[2], dims[3])\n",
    "    b3 = 0\n",
    "    \n",
    "    \n",
    "    ####################################################################################\n",
    "    ###########  TERMINA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "   \n",
    "    # Se genera el diccionario con los valores inicializados\n",
    "    parametros = {'W1': W1,\n",
    "                  'b1': b1,\n",
    "                  'W2': W2,\n",
    "                  'b2': b2,\n",
    "                  'W3': W3,\n",
    "                  'b3': b3}\n",
    "    \n",
    "    return parametros    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testeando la incialización aleatoria:\n",
      "Diferencia en W1:  1.1841719957328453e-08\n",
      "Diferencia en b1:  0.0\n",
      "Diferencia en W2:  8.297892749808612e-08\n",
      "Diferencia en b2:  0.0\n",
      "Diferencia en W3:  1.3902130737322008e-08\n",
      "Diferencia en b3:  0.0\n"
     ]
    }
   ],
   "source": [
    "# Se testea la inicialización con pesos aleatorios\n",
    "dims = [3,6,3,1]\n",
    "parametros = inicializar_pesos(dims)\n",
    "\n",
    "W1_correcto = np.array([[ 0.93781623, -0.35319773, -0.3049401 , -0.61947872,  0.49964333, -1.32879399],\n",
    "                       [ 1.00736754, -0.43948301,  0.18419731, -0.14397405,  0.84414841, -1.18942279],\n",
    "                         [-0.18614766, -0.22173389,  0.65458209, -0.63502252, -0.09955147, -0.50683179]])\n",
    "b1_correcto = np.array([0., 0., 0., 0., 0., 0.])\n",
    "W2_correcto = np.array([[ 0.01723369,  0.23793331, -0.4493259 ],[ 0.4673315 ,  0.36807287,  0.20514245],\n",
    "                       [ 0.3677729 , -0.27913073, -0.05016972], [-0.38202627, -0.10936485,  0.21651671],\n",
    "                       [-0.28236932, -0.16197395, -0.28053708], [-0.34505376, -0.27403509, -0.0051703 ]])\n",
    "b2_correcto = np.array([0., 0., 0.])  \n",
    "W3_correcto = np.array([[-0.64507943],\n",
    "       [ 0.13533997],\n",
    "       [ 0.95828723]])\n",
    "b3_correcto = np.array([0.])\n",
    "\n",
    "# Se compara la salida con la nuestra. El error debería ser e-7 o menos.\n",
    "print('Testeando la incialización aleatoria:')\n",
    "print('Diferencia en W1: ', error_relativo(parametros['W1'], W1_correcto))\n",
    "print('Diferencia en b1: ', error_relativo(parametros['b1'], b1_correcto))\n",
    "print('Diferencia en W2: ', error_relativo(parametros['W2'], W2_correcto))\n",
    "print('Diferencia en b2: ', error_relativo(parametros['b2'], b2_correcto))\n",
    "print('Diferencia en W3: ', error_relativo(parametros['W3'], W3_correcto))\n",
    "print('Diferencia en b3: ', error_relativo(parametros['b3'], b3_correcto))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Bloques Forward\n",
    "\n",
    "Se proveen las implementaciones de los métodos *forward* de los siguientes bloques: \n",
    "\n",
    "- Bloque Afin  \n",
    "- Bloque Activación donde la activación puede ser ReLU, Sigmoide\n",
    "- Bloque Afin -> Activación  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Forward Afin\n",
    "\n",
    "La señal de entrada a la activación de la capa $\\textit{l}$ puede escribirse como:\n",
    "\n",
    "$$\n",
    "\\mathbf{s}^{(l)}=\\left( W^{(l)} \\right)^T \\mathbf{x}^{(l-1)}+ \\mathbf{b}^{(l)}   \\tag{1}\n",
    "$$\n",
    "\n",
    "donde $\\mathbf{s}^{(l)}$ y $\\mathbf{b}^{(l)}$ son vectores de tamaño $d^{(l)}$, $\\mathbf{x}^{(l-1)}$  es un vector de tamaño $d^{(l-1)}$ y $W^{(l)}$ es una matriz de tamaño $d^{(l-1)} \\times d^{(l)}$.\n",
    "\n",
    "La ecuación (1) es válida cuando la entrada a la capa es un único vector $\\mathbf{x}^{(l-1)}$. En la práctica es más habitual procesar un $\\textit{batch}$ de vectores de entrada a la vez, por lo tanto es deseable contar con una expresión que genere la salida para todos los vectores de entrada a la vez. Al evitar la utilización de un bloque $\\textit{for}$ que itere por cada una de las muestras del $\\textit{batch}$ se mejora la eficiencia de la implementación.   \n",
    "\n",
    "\n",
    "La versión de la ecuación (1) que actúa sobre un conjunto de muestras a la vez es la siguiente:\n",
    "\n",
    "$$\n",
    "S^{(l)} = X^{(l-1)}W^{(l)} +b^{(l)}\\tag{2}\n",
    "$$\n",
    "\n",
    "donde $X^{[0]} = X$, siendo X una matriz que contiene un vector de características en cada fila."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def afin_forward(X, W, b):\n",
    "    \"\"\"\n",
    "    Implementa la propagación hacia adelante en una capa afin.\n",
    "\n",
    "    Entrada:\n",
    "        X: matriz de tamaño (N, dim capa anterior) que en cada fila contiene un vector de\n",
    "           activaciones de la capa anterior (o datos de entrada)\n",
    "        W: matriz de pesos de tamaño (dim de capa anterior, dim de capa actual) \n",
    "        b: vector de bias de tamaño (dim de la capa actual,)\n",
    "\n",
    "    Salida:\n",
    "        S: matriz de tamaño (N, dim de capa actual) que contiene\n",
    "           los scores o señal de entrada a la activación  \n",
    "        cache: (X, W, b) tupla que contiene X, W y b. \n",
    "               Son almacenados para calcular el paso backward eficientemente\n",
    "    \"\"\"\n",
    "\n",
    "    S = np.dot(X, W) + b\n",
    "    \n",
    "    assert(S.shape == (X.shape[0], W.shape[1] ))\n",
    "    cache = (X, W, b)\n",
    "    \n",
    "    return S, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Funciones de activación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se proveen las implementaciones de las siguientes funciones de activación:\n",
    "\n",
    "- **Sigmoide**: $\\sigma(S) = \\sigma(X W  + \\mathbf{b}) = \\frac{1}{ 1 + e^{-(X W  + b)}}$. Esta función devuelve, además de la activación resultante, la variable cache que contiene la señal `S` que dio lugar a la activación (se utiilza luego durante la propagación hacia atrás).\n",
    "\n",
    "``` python\n",
    "X, cache = sigmoid(S)\n",
    "```\n",
    "\n",
    "\n",
    "- **Rectified Linear Unit**:  $ReLU(S) = \\max(0, S)$.  Al igual que en el caso de la activación sigmoide, esta función devuelve además de la activación resultante, la variable cache que contiene la señal `S` que dio lugar a la activación (se utiilza luego durante la propagación hacia atrás).\n",
    "\n",
    "``` python\n",
    "X, cache = relu(S)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoide(S):\n",
    "    \"\"\"\n",
    "    Implementa la activación sigmoide\n",
    "    \n",
    "    Entrada:\n",
    "        S: arreglo numpy que contiene las entradas a la activación. \n",
    "           Las dimensiones de entrada no están definidas.\n",
    "    \n",
    "    Salida:\n",
    "        X: arreglo del mismo tamaño que S que contiene la salida de sigmoid(S) \n",
    "    cache: devuelve S para utilizar durante la propagación hacia atrás\n",
    "    \"\"\"\n",
    "\n",
    "    X = 1/(1+np.exp(-S))\n",
    "    cache = S\n",
    "\n",
    "    assert X.shape == S.shape, 'La entrada y la salida deben ser del mismo tamaño'\n",
    "    return X, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(S):\n",
    "    '''\n",
    "    Implementa la activación relu\n",
    "    \n",
    "    Entrada:\n",
    "        S: arreglo numpy que contiene las entradas a la activación. \n",
    "           Las dimensiones de entrada no están definidas.\n",
    "    \n",
    "    Salida:\n",
    "        X: arreglo del mismo tamaño que S que contiene la salida de relu(S) \n",
    "    cache: devuelve S para utilizar durante la propagación hacia atrás\n",
    "    '''\n",
    "    \n",
    "    X = np.maximum(0,S)\n",
    "    \n",
    "    assert(X.shape == S.shape)\n",
    "    cache = S \n",
    "        \n",
    "    return X, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - Aplicación conjunta de capa afin y activación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se provee la implementación de la propagación hacia adelante de una capa *Afin->Activacion*. El método `afin_activacion_forward()` implementa la operación:\n",
    "\n",
    "$$\n",
    "X^{[l]} = \\theta(S^{(l)}) = \\theta(X^{(l-1)}W^{(l)} +b^{(l)})\n",
    "$$\n",
    "\n",
    "donde la activación $\\theta(\\cdot)$ será alguna de las implementadas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def afin_activacion_forward(X_prev, W, b, activacion):\n",
    "    \"\"\"\n",
    "    Implementa la propagación hacia adelante para una capa Afin->Activación \n",
    "    Entrada:\n",
    "        X_prev: arreglo de tamaño (N, dim capa anterior) que contiene la \n",
    "                activación de la capa anterior (o datos de entrada):          \n",
    "        W: matriz de pesos de tamaño (dim de capa anterior, dim de capa actual)  \n",
    "        b: vector de bias de tamaño (dim de la capa actual)\n",
    "        activacion: la activacion a utilizar en esta capa se indica con uno de los \n",
    "                    siguientes strings: 'sigmoide', 'tanh' o 'relu'\n",
    "\n",
    "    Salida:\n",
    "        X: arreglo de tamaño (N, dim de capa actual) que contiene la salida \n",
    "           de la función de activación  \n",
    "    cache: tupla que contiene \"cache_afin\" y \"cache_activacion\".\n",
    "           Se almacenan para calcular la propagación hacia atrás eficientemente\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    S, cache_afin = afin_forward(X_prev,W,b)\n",
    "    \n",
    "    if activacion == 'sigmoide':    \n",
    "        \n",
    "        X, cache_activacion = sigmoide(S)\n",
    "    \n",
    "    elif activacion == 'relu':\n",
    "        \n",
    "        X, cache_activacion = relu(S)\n",
    "    \n",
    "    assert (X.shape == (X_prev.shape[0], W.shape[1]))\n",
    "    cache = (cache_afin, cache_activacion)\n",
    "\n",
    "    return X, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Función de costo\n",
    "\n",
    "En esta sección se implementarán dos funciones de costo.  \n",
    "\n",
    "- **Entropía cruzada:** Es la función de costo más utilizada en problemas de clasificación binaria. Se recuerda que la misma se define mediante la fórmula:\n",
    "$$\n",
    "H(\\mathbf{\\mathbf{x}^{(L)}}, \\mathbf{y})= -\\frac{1}{N} \\sum\\limits_{n = 1}^{N} \\left( y_n\\log x^{(L)}_n + (1-y_n)\\log\\left(1- x^{(L)}_n\\right) \\right) \\tag{3}\n",
    "$$\n",
    "\n",
    "- **Entropía cruzada regularizada:** Es la versión regularizada de la *entropía cruzada* definida anteriormente:\n",
    "$$\n",
    "H_{reg}(\\mathbf{\\mathbf{x}^{(L)}}, \\mathbf{y})= -\\frac{1}{N} \\sum\\limits_{n = 1}^{N} \\left( y_n\\log x^{(L)}_n + (1-y_n)\\log\\left(1- x^{(L)}_n\\right) \\right) + \\frac{1}{2N}\\sum_{l=1}^{L} \\Vert W_l \\Vert_2^2 \\tag{4}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte b) \n",
    "Implementar el método `entropia_cruzada_regularizada()`. De manera similar a la implementación de `entropia_cruzada()` provista, la función deberá devolver, además del costo, el gradiente del costo respecto al vector $\\mathbf{x}^{(L)}$ (salida de la red y entrada del bloque *Loss*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropia_cruzada(xL, y):\n",
    "    \"\"\"\n",
    "    Implementa la entropía cruzada\n",
    "\n",
    "    Entrada:\n",
    "        xL: vector de dimensión (N,1) que contiene las ¨probabilidades¨ de pertenecer a la clase positiva \n",
    "            estimadas por el modelo\n",
    "        y: vector de etiquetas de dimesión (N,1) (con unos para la clase positiva y 0 para la negativa)\n",
    "\n",
    "    Salida:\n",
    "        costo: escalar con el costo calculado\n",
    "        dxL: gradiente del costo respecto a xL, tiene las mismas dimensiones que xL\n",
    "    \"\"\"\n",
    "    \n",
    "    N = len(y)\n",
    "\n",
    "    logprobs = np.log(xL) * y + (1 - y) * np.log(1 - xL)\n",
    "    costo = -np.mean(logprobs)\n",
    "    \n",
    "    dxL = -(np.divide(y, xL) - np.divide(1 - y, 1 - xL))/N\n",
    "\n",
    "    costo = np.squeeze(costo) # Para asegurarnos que la salida sea un escalar (Ej: transforma [[12]] en 12).\n",
    "    assert(costo.shape == ())\n",
    "    assert(dxL.shape == xL.shape), 'Las dimensiones de dxL y xL deben ser iguales'\n",
    "    return costo, dxL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropia_cruzada_regularizada(xL, y, parametros, factor_reg):\n",
    "    \"\"\"\n",
    "    Implementa la entropía cruzada\n",
    "\n",
    "    Entrada:\n",
    "        xL: vector de dimensión (N,1) que contiene las ¨probabilidades¨ de pertenecer a la clase positiva \n",
    "            estimadas por el modelo\n",
    "        y: vector de etiquetas de dimesión (N,1) (con unos para la clase positiva y 0 para la negativa)\n",
    "        parametros: diccionario python que contiene los parametros de la red\n",
    "        factor_reg: factor de regularización\n",
    "\n",
    "    Salida:\n",
    "        costo: escalar con el costo calculado (tomando en cuenta la regularización)\n",
    "        dxL: gradiente del costo respecto a xL, tiene las mismas dimensiones que xL\n",
    "    \"\"\"\n",
    "    \n",
    "    N = len(y)\n",
    "    \n",
    "    ####################################################################################\n",
    "    ###########  EMPIEZA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "\n",
    "    costo_EC, dxL_EC = entropia_cruzada(xL, y)\n",
    "    \n",
    "    norma_matrices = np.array([np.linalg.norm(parametros[\"W\" + str(i+1)])**2 for i in range(3)])\n",
    "    \n",
    "    costo = costo_EC + (factor_reg/(2*N)) * np.sum(norma_matrices)\n",
    "    \n",
    "    dxL = dxL_EC\n",
    "    \n",
    "    ####################################################################################\n",
    "    ###########  TERMINA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "\n",
    "    costo = np.squeeze(costo) # Para asegurarnos que la salida sea un escalar (Ej: transforma [[12]] en 12).\n",
    "    assert(costo.shape == ())\n",
    "    assert(dxL.shape == xL.shape), 'Las dimensiones de dxL y xL deben ser iguales'\n",
    "    return costo, dxL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing entropia_cruzada:\n",
      "costo:  1.1244552259459768\n",
      "error en dP:  1.0993162320064296e-08\n"
     ]
    }
   ],
   "source": [
    "# Se testea la implementación de la entropía cruzada regularizada\n",
    "np.random.seed(231)\n",
    "num_classes, num_inputs = 2, 10\n",
    "xL_ = np.random.rand(num_inputs,1)\n",
    "y_ = np.random.randint(num_classes, size=(num_inputs,1))\n",
    "W1_ = np.random.randn(5, 3)\n",
    "W2_ = np.random.randn(3, 4)\n",
    "W3_ = np.random.randn(4, 1)\n",
    "param={'W1':W1_,'W2':W2_,'W3':W3_}\n",
    "lambd = 0.1\n",
    "\n",
    "dxL_num = calcular_gradiente_numerico(lambda xL: entropia_cruzada_regularizada(xL, y_, param, lambd)[0],\n",
    "                                                 xL_, verbose=False)\n",
    "costo, dxL = entropia_cruzada_regularizada(xL_, y_,  param, lambd)\n",
    "\n",
    "# Testing la entropía cruzada regularizada. El costo debería dar cercano a 1.12 y el error en dP alrededor de 1e-8\n",
    "print('\\nTesting entropia_cruzada:')\n",
    "print('costo: ', costo)\n",
    "print('error en dP: ', error_relativo(dxL_num, dxL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Propagación hacia atrás"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se implementará la versión *backward* de cada una de las funciones *forward* implementadas anteriormente. A saber:\n",
    "- AFIN backward\n",
    "- ACTIVACION backward \n",
    "- AFIN -> ACTIVACION backward donde ACTIVACION puede ser *ReLU* o *sigmoide* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 - Afin backward\n",
    "\n",
    "Durante la propagación hacia adelante en la capa $l$ (sin considerar la activación) se calcula para una muestra: \n",
    "\n",
    "$$\n",
    "\\mathbf{s}^{(l)}=\\left( W^{(l)} \\right)^T \\mathbf{x}^{(l-1)}+ \\mathbf{b}^{(l)}   \\tag{1}\n",
    "$$\n",
    "\n",
    "Si se llama $e_n$ al costo debido a la muesta $n$ y se asume conocido el *vector de sensibilidad* $\\delta^{(l)}=\\frac{\\partial e_n}{\\partial \\mathbf{s}^{(l)}}$, en el teórico del curso se vio que \n",
    "\n",
    "$$\n",
    "\\frac{\\partial{e_n}}{\\partial{W^{(l)}}}=\\mathbf{x}^{(l-1)} \\left( \\delta^{(l)} \\right)^T\n",
    "$$\n",
    "\n",
    "Análogamente a como se hizo en el caso de la propagación hacia adelante, si se considera la contribución al error de un conjunto de muestras a la vez la ecuación se puede escribir en forma vectorizada como:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial{E}}{\\partial{W^{(l)}}}= dW^{(l)} = \\left( X^{(l-1)}\\right)^ T dS^{(l)}   \\tag{5}\n",
    "$$\n",
    "\n",
    "donde $dS^{(l)}$ es una matríz de tamaño $N\\times d^{(l)}$ que en cada fila contiene el vector de sensibilidad $\\delta^{(l)}_n$ correspondiente a una de las muestras.\n",
    "\n",
    "Las derivadas respecto al vector de bias $\\mathbf{b}^{(l)}$ se calculan de forma similar (puede pensarse como un caso particular en que $X^{(l-1)}$ es un vector columna de unos) por lo que\n",
    "\n",
    "$$\n",
    "\\frac{\\partial{E}}{\\partial{\\mathbf{b}^{(l)}}}= d\\mathbf{b}^{(l)} =\\mathbb{1} ^ T dS^{(l)}  \\tag{6}\n",
    "$$\n",
    "\n",
    "Finalmente se calcula la influencia de cada una de las características en el error. Considerando primero el caso de una muestra, se tiene que:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial{e_n}}{\\partial{\\mathbf{x}^{(l-1)}}} = W^{(l)} \\delta^{(l)}\n",
    "$$\n",
    "\n",
    "que en forma vectorizada puede escribirse como:\n",
    "\n",
    "$$ \n",
    " \\frac{\\partial E }{\\partial X^{(l-1)}} = dX^{(l-1)} = dS^{(l)} \\left( W^{(l) }\\right)^T \\tag{7}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte c) \n",
    "Implementar el método `afin_backward()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def afin_backward(dS, cache):\n",
    "    \"\"\"\n",
    "    Implementa la propagación hacia atrás para una capa l (sin considerar la activación)\n",
    "\n",
    "    Entrada:\n",
    "        dS: Gradiente de la función de costo con respecto a la salida de la capa actual \n",
    "            (sin considerar la activación)\n",
    "        cache: tupla de valores (X_prev, W, b) calculados durante la propagación hacia adelante\n",
    "               de la capa actual\n",
    "\n",
    "    Salida:\n",
    "        dX_prev: Gradiente de la función de costo con respecto a la activación de la capa anterior (l-1), \n",
    "                 tiene el mismo tamaño que X_prev\n",
    "        dW: Gradiente de la función de costo con respecto a W (de la capa actual l), \n",
    "            tiene el mismo tamaño que W\n",
    "        db: Gradiente de la función de costo con respecto a b (de la capa actual l), \n",
    "            tiene el mismo tamaño que b\n",
    "    \"\"\"\n",
    "    X_prev, W, b = cache\n",
    "    N = X_prev.shape[0]\n",
    "\n",
    "    ####################################################################################\n",
    "    ###########  EMPIEZA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "\n",
    "    dX_prev = dS @ W.T\n",
    "    \n",
    "    dW = X_prev.T @ dS\n",
    "    \n",
    "    db = np.ones((N,1)) @ dS\n",
    "    \n",
    "    ####################################################################################\n",
    "    ###########  TERMINA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "\n",
    "    assert (dX_prev.shape == X_prev.shape)\n",
    "    assert (dW.shape == W.shape)\n",
    "    assert (db.shape == b.shape)\n",
    "    \n",
    "    return dX_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 10 is different from 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_32130/1789857061.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mafin_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mafin_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# El error debería ser del orden de e-9 o menos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_32130/2990001506.py\u001b[0m in \u001b[0;36mafin_backward\u001b[0;34m(dS, cache)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mdW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_prev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mdS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mdS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m####################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 10 is different from 1)"
     ]
    }
   ],
   "source": [
    "# Test de afin_backward\n",
    "np.random.seed(43)\n",
    "x = np.random.randn(10, 6)\n",
    "w = np.random.randn(6, 5)\n",
    "b = np.random.randn(5)\n",
    "dout = np.random.randn(10, 5)\n",
    "\n",
    "#dx_num = calcular_gradiente_numerico_array(lambda x: afin_forward(x, w, b)[0], x, dout)\n",
    "dx_num = calcular_gradiente_numerico_array(lambda xx: afin_forward(xx, w, b)[0], x, dout)\n",
    "\n",
    "dw_num = calcular_gradiente_numerico_array(lambda ww: afin_forward(x, ww, b)[0], w, dout)\n",
    "db_num = calcular_gradiente_numerico_array(lambda bb: afin_forward(x, w, bb)[0], b, dout)\n",
    "\n",
    "_, cache = afin_forward(x, w, b)\n",
    "dx, dw, db = afin_backward(dout, cache)\n",
    "\n",
    "# El error debería ser del orden de e-9 o menos\n",
    "print('Testing afin_backward():')\n",
    "print('dx error: ', error_relativo(dx_num, dx))\n",
    "print('dw error: ', error_relativo(dw_num, dw))\n",
    "print('db error: ', error_relativo(db_num, db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 - Activación backward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si  $\\theta(\\cdot)$ es la función de activación, entonces su función *backward* se calcula \n",
    "\n",
    "$$\n",
    "dS^{(l)} = dX^{(l)} * \\theta'(S^{(l)})   \\tag{8}\n",
    "$$.  \n",
    "\n",
    "donde $\\theta'(\\cdot)$ debe ser calculado para cada caso. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte d) \n",
    "Implementar los métodos *backward* cada una de las funciones de activación implementadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoide_backward(dX, cache):\n",
    "    \"\"\"\n",
    "    Implementa la propagación hacia atrás de una activación Sigmoide.\n",
    "\n",
    "    Entrada:\n",
    "        dX: gradiente de la función de costo respecto a la salida de la capa sigmoide,\n",
    "              el tamaño del arreglo no está definido\n",
    "        cache: 'S' valor almacenado durante la propagación hacia adelante\n",
    "\n",
    "    Returns:\n",
    "    dS -- Gradiente del costo respecto a S\n",
    "    \"\"\"\n",
    "    \n",
    "    S = cache\n",
    "    \n",
    "    ####################################################################################\n",
    "    ###########  EMPIEZA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "    \n",
    "    \n",
    "    dS = dX * (np.exp(-S) /(1+np.exp(-S))**2)\n",
    "    \n",
    "     \n",
    "    ####################################################################################\n",
    "    ###########  TERMINA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "    \n",
    "    assert (dS.shape == S.shape), 'dS y S no tienen el mismo tamaño'\n",
    "    assert (dX.shape == S.shape), 'dX y S no tienen el mismo tamaño'\n",
    "    \n",
    "    return dS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing relu_backward():\n",
      "dS error:  3.44651192693257e-11\n"
     ]
    }
   ],
   "source": [
    "# Test de sigmoid_backward\n",
    "np.random.seed(231)\n",
    "S = np.random.randn(10, 10)\n",
    "dout = np.random.randn(*S.shape)\n",
    "\n",
    "dS_num = calcular_gradiente_numerico_array(lambda S: sigmoide(S)[0], S, dout)\n",
    "\n",
    "_, cache = sigmoide(S)\n",
    "dS = sigmoide_backward(dout, cache)\n",
    "\n",
    "# El error debería ser del orden de e-10 o menos\n",
    "print('Testing relu_backward():')\n",
    "print('dS error: ', error_relativo(dS_num, dS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_backward(dX, cache):\n",
    "    \"\"\"\n",
    "    Implementa la propagación hacia atrás de una activación ReLu.\n",
    "\n",
    "    Entrada:\n",
    "        dX: gradiente de la función de costo respecto a la salida de la capa relu,\n",
    "              el tamaño del arreglo no está definido\n",
    "        cache: 'S' valor almacenado durante la propagación hacia adelante\n",
    "\n",
    "    Returns:\n",
    "    dS -- Gradiene del costo respecto a S\n",
    "    \"\"\"\n",
    "    \n",
    "    S = cache\n",
    "    \n",
    "    ####################################################################################\n",
    "    ###########  EMPIEZA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "\n",
    "    dS = dX * (S > 0)\n",
    "    \n",
    "    ####################################################################################\n",
    "    ###########  TERMINA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "    \n",
    "    assert (dS.shape == S.shape)\n",
    "    \n",
    "    return dS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing relu_backward():\n",
      "dS error:  3.2756349136310288e-12\n"
     ]
    }
   ],
   "source": [
    "# Test de relu_backward\n",
    "np.random.seed(231)\n",
    "x = np.random.randn(10, 10)\n",
    "dout = np.random.randn(*x.shape)\n",
    "\n",
    "dS_num = calcular_gradiente_numerico_array(lambda x: relu(x)[0], x, dout)\n",
    "\n",
    "_, cache = relu(x)\n",
    "dS = relu_backward(dout, cache)\n",
    "\n",
    "# El error debería ser del orden de e-12\n",
    "print('Testing relu_backward():')\n",
    "print('dS error: ', error_relativo(dS_num, dS))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 - Afin --> Activacion backward\n",
    "\n",
    "A continuación se implementará la función que realiza la propagación hacia atrás del la capa *Afin-->Activacion*. \n",
    "\n",
    "### Parte e) \n",
    "Implementar la función `afin_activacion_backward()`. Para ello utilizar las funciones implementadas anteriormente: `afin_backward` y la ¨`activacion_backward`¨ que corresponda. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def afin_activacion_backward(dX, cache, activacion):\n",
    "    '''\n",
    "    Implementar la propagación hacia atrás para la capa Afin->Activacion.\n",
    "    \n",
    "    Entradas:\n",
    "        dX: gradiente del costo respecto a la salida de la capa actual \n",
    "        cache: tupla con los valores(cache_afin, cache_activacion) \n",
    "        activacion: la activación a utilizar en esta capa, puede ser 'sigmoide' o 'relu'\n",
    "    Salidas:\n",
    "        dX_prev: Gradiente del costo con respecto a la activación de la capa anterior(l-1), \n",
    "                 tiene las mismas dimensiones que X_prev\n",
    "        dW -- Gradiente del costo con respecto a W (de la capa actual l), \n",
    "              tiene las mismas dimensiones que W\n",
    "        db -- Gradiente del costo con respecto a b (de la capa actual l), \n",
    "              tiene las mismas dimensiones que b\n",
    "    '''\n",
    "    cache_afin, cache_activacion = cache\n",
    "    \n",
    "    ####################################################################################\n",
    "    ###########  EMPIEZA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "    \n",
    "    if activacion == 'relu':\n",
    "        dS = relu_backward(dX, cache_activacion)\n",
    "\n",
    "    elif activacion == 'sigmoide':\n",
    "        dS = sigmoide_backward(dX, cache_activacion)\n",
    "        \n",
    "    dX_prev, dW, db = afin_backward(dS, cache_afin)\n",
    "       \n",
    "\n",
    "    ####################################################################################\n",
    "    ###########  TERMINA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "    \n",
    "    return dX_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing afin_relu_forward y afin_relu_backward:\n",
      "dx error:  2.299579177309368e-11\n",
      "dw error:  8.162011105764925e-11\n",
      "db error:  7.826724021458994e-12\n",
      "Testing afin_sigmoide_forward y afin_sigmoide_backward:\n",
      "dx error:  1.2457054025023588e-10\n",
      "dw error:  2.7821293383972562e-09\n",
      "db error:  1.5238194515875374e-10\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(231)\n",
    "x = np.random.randn(2, 12)\n",
    "w = np.random.randn(12, 10)\n",
    "b = np.random.randn(10)\n",
    "dout = np.random.randn(2, 10)\n",
    "\n",
    "activaciones = ['relu', 'sigmoide']\n",
    "\n",
    "for activacion in activaciones:\n",
    "    out, cache = afin_activacion_forward(x, w, b, activacion)\n",
    "    dx, dw, db = afin_activacion_backward(dout, cache, activacion)\n",
    "\n",
    "    dx_num = calcular_gradiente_numerico_array(lambda x: afin_activacion_forward(x, w, b, activacion)[0], x, dout)\n",
    "    dw_num = calcular_gradiente_numerico_array(lambda w: afin_activacion_forward(x, w, b, activacion)[0], w, dout)\n",
    "    db_num = calcular_gradiente_numerico_array(lambda b: afin_activacion_forward(x, w, b, activacion)[0], b, dout)\n",
    "\n",
    "    # Los errores deberían ser del orden de e-9 o menos\n",
    "    print('Testing afin_' + activacion + '_forward y afin_' + activacion + '_backward:')\n",
    "    print('dx error: ', error_relativo(dx_num, dx))\n",
    "    print('dw error: ', error_relativo(dw_num, dw))\n",
    "    print('db error: ', error_relativo(db_num, db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  5 - Actualización de los parámetros\n",
    "\n",
    "En esta sección se actualizarán los parámetros del modelo mediante el método de *descenso por gradiente*:\n",
    "\n",
    "$$ W^{(l)} = W^{(l)} -\\eta \\text{ } dW^{(l)} \\tag{9}$$\n",
    "$$ \\mathbf{b}^{(l)} = \\mathbf{b}^{(l)} -\\eta \\text{ } \\mathbf{db}^{(l)} \\tag{10}$$\n",
    "\n",
    "donde $\\eta$ es el *learning rate*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte f) \n",
    "Implementar `actualizar_parametros()` para actualizar los parámetros usando *descenso por gradiente*. Luego de actualizar los parámetros, almacenarlos en el diccionario de parámetros. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actualizar_parametros(parametros, gradientes, learning_rate):\n",
    "    \"\"\"\n",
    "    Se actualizan los parámetros utilizando descenso por gradiente. Si bien en este notebook se trabaja \n",
    "    con una red de dos capas, el método se implementa en forma genérica para mostrar como se haría en el\n",
    "    caso más general.\n",
    "    \n",
    "    Entrada:\n",
    "        parametros: diccionario de python que contiene los parámetros \n",
    "        gradientes: diccionario de python que contiene los gradientes \n",
    "                    (las salidas de los métodos backward)\n",
    "    \n",
    "    Salida:\n",
    "        parametros: diccionario de python que contiene los parámetros actualizados \n",
    "                    parametros[\"W\" + str(l)] = ... \n",
    "                    parametros[\"b\" + str(l)] = ...\n",
    "    \"\"\"\n",
    "    \n",
    "    L = len(parametros) // 2 # número de capas en la red neuronal\n",
    "    \n",
    "    # Se actualiza cada uno de los parámetros. En el caso de una red profunda de L capas\n",
    "    # se hace con un loop que va recorriendo cada parámetro\n",
    "    for l in range(1,L+1):\n",
    "        \n",
    "        ####################################################################################\n",
    "        ###########  EMPIEZA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "        ####################################################################################\n",
    "        \n",
    "        parametros[\"W\"+str(l)] = parametros[\"W\"+str(l)] - learning_rate * gradientes[\"W\"+str(l)]\n",
    "        \n",
    "        parametros[\"b\"+str(l)] = parametros[\"b\"+str(l)] - learning_rate * gradientes[\"b\"+str(l)]\n",
    "        \n",
    "        ####################################################################################\n",
    "        ###########  TERMINA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "        ####################################################################################\n",
    "    \n",
    "    return parametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación utilizando datos sintéticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aux_datos import load_2D_dataset, mostrar_frontera_decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se generan datos sintéticos con forma de flor pertenecientes a dos clases: $cero$ y $uno$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(211, 2) (211, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test = load_2D_dataset()\n",
    "print(X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Se muestran los datos\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=Y_train.ravel(), s=40, cmap=plt.cm.Spectral);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red para clasificar los datos sintéticos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para clasificar los datos sintéticos se utilizará una red de **tres capas** con la siguiente arquitectura:   \n",
    "\n",
    "*Afin->Relu->Afin->Relu-->Afin-->Sigmoide* \n",
    "\n",
    "### Parte g)  \n",
    "Completar la implementación del método `red_tres_capas()` utilizando los métodos *forward* y *backward* adecuados para dicha arquitectura. Como función de costo se utilizará la *entropía cruzada*.\n",
    "\n",
    "**Nota:** La función tiene previsto un parámetro para indicar si se aplica o no regularización y otro parámetro para el factor de regularización. En esta parte no hay que utilizar ninguno de estos parámetros, o bien asumir que `regularizar` es `False`. La regularización se implementará en una parte posterior.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def red_tres_capas(X, Y, dims_capas, num_iter = 1000, learning_rate = 1,\n",
    "                    mostrar_costo=False, semilla=100, regularizar=False, reg_factor=1):\n",
    "    \"\"\"\n",
    "    Implementa una red neuronal de tres capas: Afin -> Relu -> Afin -> Relu -> Afin -> Sigmoide.\n",
    "    \n",
    "    Entrada:\n",
    "        X: datos de entrada, de tamaño (N, d_0)\n",
    "        Y: etiquetas (1 para la clase positiva y 0 para la negativa), de tamaño (N,1)\n",
    "        dims_capas: dimensiones de las capas(d_0, d_1, d_2, d_3)\n",
    "        num_iter: número de iteraciones del loop de optimización\n",
    "        learning_rate: learning rate utilizado para la actualización mediante descenso por gradiente\n",
    "        mostrar_costo: Si vale True, se muestra el costo cada 100 iteraciones \n",
    "        semilla: semilla utilizada para la generación de números aleatorios\n",
    "        regularizar: indica si se aplica o no regularización\n",
    "        reg_factor: factor de regularización\n",
    "    Salida:\n",
    "        parametros: un diccionario de python que contiene W1, W2, W3, b1, b2 and b3\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(semilla)\n",
    "    gradientes = {} # se inicializa el diccionario que almacena los gradientes\n",
    "    costos = []     # lista que almacena el costo\n",
    "    N = X.shape[0]  # número de muestras\n",
    "    \n",
    "    # Se inicializan los parámetros del diccionario llamando a una de las \n",
    "    # funciones previamente implementadas\n",
    "    parametros = inicializar_pesos(dims_capas, semilla=semilla)\n",
    "     \n",
    "    # Se obtienen W1, b1, W2 y b2 del diccionario de parámetros.\n",
    "    W1 = parametros[\"W1\"]\n",
    "    b1 = parametros[\"b1\"]\n",
    "    W2 = parametros[\"W2\"]\n",
    "    b2 = parametros[\"b2\"]\n",
    "    W3 = parametros[\"W3\"]\n",
    "    b3 = parametros[\"b3\"]\n",
    "    # Loop (descenso por gradiente)\n",
    "\n",
    "    for i in range(0, num_iter):\n",
    "\n",
    "        ####################################################################################\n",
    "        ###########  EMPIEZA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "        ####################################################################################\n",
    "        \n",
    "        # Propagación hacia adelante: Afin -> Relu -> Afin -> Relu -> Afin -> Sigmoide. \n",
    "        # Entradas: \"X, W1, b1\". Salidas: \"X1, cache1, X2, cache2, X3, cache3\".\n",
    "        X1, cache1 = afin_activacion_forward(X, W1, b1, \"relu\")\n",
    "        \n",
    "        X2, cache2 = afin_activacion_forward(X1, W2, b2, \"relu\")\n",
    "        \n",
    "        X3, cache3 = afin_activacion_forward(X2, W3, b3, \"sigmoide\")\n",
    "        \n",
    "        \n",
    "        # Se calcula el costo y se inicia la propagación hacia atrás\n",
    "        if regularizar:\n",
    "            costo, dX3 = entropia_cruzada_regularizada(X3, Y, parametros, factor_reg=reg_factor)\n",
    "        else:\n",
    "            costo, dX3 = entropia_cruzada(X3, Y)\n",
    "        \n",
    "        # Propagación hacia atrás. \n",
    "        # Entradas: \"dX3, cache3, cache2, cache1\". \n",
    "        # Salidas: \"dX2, dW3, db3, dX1, dW2, db2, dW1, db1, dX0 (no utilizado)\".\n",
    "        \n",
    "        dX2, dW3, db3 = afin_activacion_backward(dX3, cache3, \"sigmoide\")\n",
    "        dX1, dW2, db2 = afin_activacion_backward(dX2, cache2, \"relu\")\n",
    "        dX0, dW1, db1 = afin_activacion_backward(dX1, cache1, \"relu\")\n",
    "        \n",
    "        # Se almacenan los gradientes recientemente calculados en el diccionario \n",
    "        gradientes[\"W1\"] = dW1\n",
    "        gradientes[\"b1\"] = db1\n",
    "        gradientes[\"W2\"] = dW2\n",
    "        gradientes[\"b2\"] = db2\n",
    "        gradientes[\"W3\"] = dW3\n",
    "        gradientes[\"b3\"] = db3\n",
    "        \n",
    "        \n",
    "        # Se actualizan los parámetros\n",
    "        parametros = actualizar_parametros(parametros, gradientes, learning_rate=learning_rate)\n",
    "        \n",
    "        \n",
    "        ####################################################################################\n",
    "        ###########  TERMINA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "        ####################################################################################\n",
    "\n",
    "        # Se obtienen los nuevos W1, b1, W2, b2, W3 y b3 del diccionario de parámetros.        \n",
    "        W1 = parametros[\"W1\"] \n",
    "        b1 = parametros[\"b1\"]\n",
    "        W2 = parametros[\"W2\"]\n",
    "        b2 = parametros[\"b2\"]\n",
    "        W3 = parametros[\"W3\"]\n",
    "        b3 = parametros[\"b3\"]\n",
    "\n",
    "        \n",
    "        # Se muestra la evolución del costo cada 100 iteraciones\n",
    "        if mostrar_costo and i % 1000 == 0:\n",
    "            print(\"Costo luego de iteracion {}: {}\".format(i, np.squeeze(costo)))\n",
    "\n",
    "        if mostrar_costo and i % 1000 == 0:\n",
    "            costos.append(costo)\n",
    "    \n",
    "    # se muestra el costo\n",
    "    if mostrar_costo:    \n",
    "        plt.plot(np.squeeze(costos))\n",
    "        plt.ylabel('costo')\n",
    "        plt.xlabel('iteraciones (sobre 100)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "    \n",
    "    return parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Se definen las constantes que determinan la arquitectura de la red ####\n",
    "d_0 = X_train.shape[1]   \n",
    "d_1 = 20\n",
    "d_2 = 3\n",
    "d_3 = 1\n",
    "#dims_capas = [d_0, d_1, d_2, d_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_32130/2102214149.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Se entrena la red, con los parámetros por defecto el costo debería ser alrededor de 0.65 en la iteración 0 y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# menor a 0.15 en la 20000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m parametros_red_3capas = red_tres_capas(X_train, Y_train, dims_capas = [d_0, d_1, d_2, d_3], \n\u001b[0m\u001b[1;32m      4\u001b[0m                                     \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m38000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmostrar_costo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                     regularizar=False)\n",
      "\u001b[0;32m/tmp/ipykernel_32130/3183613283.py\u001b[0m in \u001b[0;36mred_tres_capas\u001b[0;34m(X, Y, dims_capas, num_iter, learning_rate, mostrar_costo, semilla, regularizar, reg_factor)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# Salidas: \"dX2, dW3, db3, dX1, dW2, db2, dW1, db1, dX0 (no utilizado)\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mdX2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdW3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mafin_activacion_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdX3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sigmoide\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mdX1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdW2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mafin_activacion_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdX2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mdX0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdW1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mafin_activacion_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdX1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_32130/3763727012.py\u001b[0m in \u001b[0;36mafin_activacion_backward\u001b[0;34m(dX, cache, activacion)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mdS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoide_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_activacion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mdX_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mafin_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_afin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_32130/1402079497.py\u001b[0m in \u001b[0;36mafin_backward\u001b[0;34m(dS, cache)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdX_prev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mX_prev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdX_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# Se entrena la red, con los parámetros por defecto el costo debería ser alrededor de 0.65 en la iteración 0 y \n",
    "# menor a 0.15 en la 20000\n",
    "parametros_red_3capas = red_tres_capas(X_train, Y_train, dims_capas = [d_0, d_1, d_2, d_3], \n",
    "                                    learning_rate = 0.2, num_iter = 38000, mostrar_costo=True,\n",
    "                                    regularizar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mostrar la frontera de decisión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte h)  \n",
    "Mostrar la frontera de decisión. Para ello se deberá completar primero la implementación del método `predecir_clase_datos_sinteticos()`. Dicho método utiliza los parámetros de la red recientemente encontrados para predecir la clase de los vectores de características pasados como parámetro. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predecir_clase_datos_sinteticos(X, parametros):\n",
    "    \"\"\"\n",
    "    Esta función predice la clase de los datos sintéticos. \n",
    "    \n",
    "    Entrada:\n",
    "        X: matriz de tamaño Nx2 que en cada fila contiene un vector de características\n",
    "        parametros: parametros del modelo ya entrenado\n",
    "    \n",
    "    Salida:\n",
    "        p : vector de tamaño Nx1 que contiene las predicciones realizadas (0 o 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Se obtienen W1, b1, W2, b2, W3 y b3 del diccionario de parámetros.\n",
    "    W1 = parametros[\"W1\"]\n",
    "    b1 = parametros[\"b1\"]\n",
    "    W2 = parametros[\"W2\"]\n",
    "    b2 = parametros[\"b2\"]\n",
    "    W3 = parametros[\"W3\"]\n",
    "    b3 = parametros[\"b3\"]\n",
    "    \n",
    "    N = X.shape[0]\n",
    "    p = np.zeros((N,1))\n",
    "    \n",
    "    ####################################################################################\n",
    "    ###########  EMPIEZA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "    \n",
    "    # Se hace la propagación hacia adelante de los datos de entrada X. Tener en cuenta que la\n",
    "    # arquitectura utilizada en la red fue Afin-->Relu-->Afin-->Relu-->Afin-->Sigmoide\n",
    "    # ~ 3 lineas de codigo\n",
    "\n",
    "    \n",
    "    # Se obtienen las predicciones. Si la salida es mayor que 0.5 se asigna la clase 1, de lo \n",
    "    # contrario se asigna 0\n",
    "    # ~ 1 linea de codigo\n",
    "\n",
    "    \n",
    "    ####################################################################################\n",
    "    ###########  TERMINA ESPACIO PARA COMPLETAR CODIGO  ################################\n",
    "    ####################################################################################\n",
    "\n",
    "        \n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente celda muestra el porcentaje de acierto con el conjunto de entrenamiento. Verificar que para los parámetros por defecto es mayor al 95%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones_train = predecir_clase_datos_sinteticos(X_train, parametros_red_3capas)\n",
    "porcentaje_aciertos = np.mean(predicciones_train==Y_train)\n",
    "print('El porcentaje de aciertos es %f' % porcentaje_aciertos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se muestra la frontera de decisión. Verificar que es razonable para el conjunto de entrenamiento.\n",
    "mostrar_frontera_decision(lambda x: predecir_clase_datos_sinteticos(x, parametros_red_3capas), X_train, Y_train.flatten())\n",
    "plt.title('Frontera de decisión para una capa oculta de ' + str(d_1) + ' nodos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte i)\n",
    "Modificar la implementación de `red_tres_capas()` de modo que cuando se pase como parámetro `regularizar=True` utilice como función de costo `entropia_cruzada_regularizada()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Con regularización\n",
    "parametros_red_3capas_regularizada = red_tres_capas(X_train, Y_train, dims_capas = [d_0, d_1, d_2, d_3], \n",
    "                                                    learning_rate = 0.2, num_iter = 38000, mostrar_costo=True,\n",
    "                                                    regularizar=True, reg_factor=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones_train = predecir_clase_datos_sinteticos(X_train, parametros_red_3capas_regularizada)\n",
    "porcentaje_aciertos = np.mean(predicciones_train==Y_train)\n",
    "print('El porcentaje de aciertos es %f' % porcentaje_aciertos)\n",
    "\n",
    "# Se muestra la frontera de decisión. Verificar que es razonable para el conjunto de entrenamiento.\n",
    "mostrar_frontera_decision(lambda x: predecir_clase_datos_sinteticos(x, parametros_red_3capas_regularizada), X_train, Y_train.flatten())\n",
    "plt.title('Frontera de decisión para una capa oculta de ' + str(d_1) + ' nodos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte j)\n",
    "¿Considera que el valor por defecto (1e-3) del factor de regularización es adecuado? Comente como influye este factor en la solución y cómo eligiría su valor más adecuado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
